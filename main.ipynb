{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Curso de Visão Computacional\n",
    "\n",
    "## Aula 1 - Entendendo o problema\n",
    "\n",
    "### Preparando o ambiente\n",
    "\n",
    "Para o curso de visão computacional, vamos utilizar a biblioteca OpenCV e a interface pytesseract, que interage com o Tesseract da Google. Para instalar o OpenCV, basta executar o comando abaixo:\n",
    "\n",
    "```bash\n",
    "pip install opencv-python\n",
    "```\n",
    "Para instalar o pytesseract, basta executar o comando abaixo:\n",
    "\n",
    "```bash\n",
    "pip install pytesseract\n",
    "```\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a93132f2b5370cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exemplo de uso\n",
    "\n",
    "Vamos utilizar o pytesseract para extrair o texto de uma imagem. Para isso, vamos utilizar a imagem abaixo:\n",
    "\n",
    "![Trecho do livro \"The Witcher\"](imagens/trecho_livro.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50dde0815ee8c12d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import seaborn as sns\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4031604d800d03f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Carregando a imagem\n",
    "image_file_path = os.getcwd() + '/imagens/trecho_livro.png'\n",
    "image = cv2.imread(image_file_path)\n",
    "# Exibindo a imagem\n",
    "# cv2.imshow('image', image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # It helps when Turn off axes to remove the axis ticks and labels\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c02a00027ce0bc4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from google.colab.patches import cv2_imshow\n",
    "# \n",
    "# cv2_imshow(image)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41250191ae22a20d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Com o Tesseract é possível extrair o texto da imagem. Para isso, vamos utilizar o método `image_to_string` do pytesseract. O código abaixo extrai o texto da imagem e imprime na tela."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7203fc4fdc2a6840"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "texto = pytesseract.image_to_string(image)\n",
    "print(texto)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6743ace3ef7819c3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Através do output acima podemos perceber que o Tesseract não extraiu de maneira tão eficiente o texto da imagem. Para melhorarmos a sua eficiência podemos passar alguns parâmetros para o método `image_to_string`:\n",
    "\n",
    "1. `tessdata-dir`: Diretório onde estão os arquivos de treinamento do Tesseract.\n",
    "2. `psm`: Modo de segmentação de página. O valor 6 é utilizado para segmentação de bloco de texto."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a3c5ace582b8404"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tesseract_config = \"--tessdata-dir tessdata --psm 6\"\n",
    "\n",
    "texto = pytesseract.image_to_string(image, config=tesseract_config, lang=\"por\")\n",
    "print(texto)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "628c68fe36dfc3bc",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trabalhando com placas de veículos\n",
    "\n",
    "Vamos utilizar o pytesseract para extrair o texto de uma placa de veículo. Para isso, vamos utilizar a imagem abaixo:\n",
    "\n",
    "![Placa de veículo](imagens/placa_carro1.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19e9957e168b84a6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Lendo a imagem\n",
    "image_file_path = os.getcwd() + '/imagens/placa_carro1.png'\n",
    "image = cv2.imread(image_file_path)\n",
    "\n",
    "# Exibindo a imagem\n",
    "# cv2.imshow('image', image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image_rgb)\n",
    "plt.axis('off')  # It helps when Turn off axes to remove the axis ticks and labels\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ade7d01cb59a615",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Antes de extrairmos o texto da imagem, precisamos realizar algumas operações de pré-processamento. Primeiramente, vamos converter a imagem para escala de cinza:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17889cc574431302"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Convertendo a imagem para escala de cinza\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imwrite('imagens/outputs/gray_image.png', gray_image)\n",
    "\n",
    "# Exibindo a imagem em escala de cinza\n",
    "# cv2.imshow('gray_image', gray_image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "gray_image_rgb = cv2.cvtColor(gray_image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(gray_image_rgb)\n",
    "plt.axis('off')  # It helps when Turn off axes to remove the axis ticks and labels\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56846ba7bc8972ee",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tesseract_config = \"--tessdata-dir tessdata\"\n",
    "texto = pytesseract.image_to_string(gray_image, config=tesseract_config, lang=\"por\")\n",
    "\n",
    "print(texto)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12789a91dcbe1755",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Limiarização\n",
    "\n",
    "Ao rodarmos a célula acima percebemos que o Tesseract não conseguiu extrair o texto da placa de veículo, ainda que a imagem esteja em escala de cinza. Vamos aplicar a limiarização na imagem para melhorar a extração do texto através do método `cv2.threshold`:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4a200699e54f098"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Aplicando a limiarização\n",
    "_, threshold_image = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY)\n",
    "cv2.imwrite('imagens/outputs/threshold_image.png', threshold_image)\n",
    "# Exibindo a imagem limiarizada\n",
    "# cv2.imshow('threshold_image', threshold_image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "threshold_image = cv2.cvtColor(threshold_image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(threshold_image)\n",
    "plt.axis('off')  # It helps when Turn off axes to remove the axis ticks and labels\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eaa66874d68fb5bc",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Existem outros tipos de limiarização, tais como o a Limiarização Adaptativa e a Limiarização de Otsu. Vamos ver cada uma delas:\n",
    "\n",
    "### Limiarização Adaptativa\n",
    "\n",
    "Este tipo de limiarização é utilizado quando a imagem possui iluminação variável. A limiarização adaptativa calcula o limiar para pequenas regiões da imagem. Para isso, vamos utilizar o método `cv2.adaptiveThreshold` com dois tipos diferentes de cálculo do limiar: `cv2.ADAPTIVE_THRESH_MEAN_C` e `cv2.ADAPTIVE_THRESH_GAUSSIAN_C`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9793b962b4481a3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lim_adapt_mean = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 8)\n",
    "cv2.imwrite('imagens/outputs/lim_adapt_mean.png', lim_adapt_mean)\n",
    "\n",
    "lim_adapt_mean_rgb = cv2.cvtColor(lim_adapt_mean, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(lim_adapt_mean_rgb)\n",
    "plt.axis('off')  # It helps when Turn off axes to remove the axis ticks and labels\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2b7cd2e0dec5b94",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lim_adapt_gaussian = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 8)\n",
    "cv2.imwrite('imagens/outputs/lim_adapt_gaussian.png', lim_adapt_gaussian)\n",
    "\n",
    "lim_adapt_gaussian_rgb = cv2.cvtColor(lim_adapt_gaussian, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(lim_adapt_gaussian_rgb)\n",
    "plt.axis('off')  # It helps when Turn off axes to remove the axis ticks and labels\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec4548e1b207a7db",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Limiarização de Otsu\n",
    "\n",
    "A limiarização de Otsu utiliza um algoritmo que calcula o limiar ótimo para a imagem ao analisar o histograma da intensidade dos pixels da imagem. Para isso, vamos utilizar o método `cv2.threshold` com o tipo `cv2.THRESH_OTSU`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1137745b6c69d348"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "image"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab424730a49c1a67",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ax = sns.histplot(image.flatten())\n",
    "ax.figure.set_size_inches(10, 6)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d40f76a349b95e21",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lim, lim_otsu = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "cv2.imwrite('imagens/outputs/lim_otsu.png', lim_otsu)\n",
    "\n",
    "print(f\"Limiar de Otsu: {lim}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "675401aa194586e1",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformações Morfológicas\n",
    "\n",
    "As transformações morfológicas são operações que processam a forma de uma imagem. Normalmente, são aplicadas em imagens binárias. As operações mais comuns são a erosão e a dilatação.\n",
    "\n",
    "- **Erosão**: A operação de erosão remove pixels da borda dos objetos na imagem. O kernel desliza pela imagem (da esquerda para a direita e de cima para baixo). Um pixel na imagem binária é definido como 1 se todos os pixels sob o kernel forem 1, caso contrário, ele é erodido (definido como 0).\n",
    "- **Dilatação**: A operação de dilatação faz o oposto da erosão. O kernel desliza pela imagem. Um pixel na imagem binária é definido como 1 se pelo menos um pixel sob o kernel for 1."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5eb12bf3557e10ed"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Definindo um kernel para utilizar nas transformações\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2618b22f92ea96b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "erosion = cv2.erode(lim_otsu, kernel)\n",
    "cv2.imwrite('imagens/outputs/erosion.png', erosion)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df3b631b1403c2cd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dilation = cv2.dilate(lim_otsu, kernel)\n",
    "cv2.imwrite('imagens/outputs/dilation.png', dilation)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "424335bea687ab80",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "A partir da erosão e dilatação, podemos realizar outras operações morfológicas, tais como a abertura e o fechamento.\n",
    "\n",
    "- **Abertura**: A operação de abertura é útil para remover ruídos brancos. Consiste em aplicar a erosão seguida da dilatação.\n",
    "- **Fechamento**: A operação de fechamento é útil para remover ruídos pretos. Consiste em aplicar a dilatação seguida da erosão."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9de71f2892dc29c4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "abertura = cv2.morphologyEx(lim_otsu, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imwrite('imagens/outputs/abertura.png', abertura)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0aee51801fe0d0c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fechamento = cv2.morphologyEx(lim_otsu, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imwrite('imagens/outputs/fechamento.png', fechamento)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92c789650f136a20",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Por último vamos falar sobre as transformações top hat, black hat e gradient.\n",
    "\n",
    "- **Top Hat**: A transformação top hat é a diferença entre a imagem original e a imagem aberta. Utilizada para realçar detalhes claros.\n",
    "- **Black Hat**: A transformação black hat é a diferença entre a imagem fechada e a imagem original. Utilizada para realçar detalhes escuros.\n",
    "- **Gradient**: A transformação gradient é a diferença entre a dilatação e a erosão da imagem. Utilizada para realçar bordas."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78105709be3d94cb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "top_hat = cv2.morphologyEx(lim_otsu, cv2.MORPH_TOPHAT, kernel)\n",
    "cv2.imwrite('imagens/outputs/top_hat.png', top_hat)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b9b6dca739f6d11",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "black_hat = cv2.morphologyEx(lim_otsu, cv2.MORPH_BLACKHAT, kernel)\n",
    "cv2.imwrite('imagens/outputs/black_hat.png', black_hat)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fad3f04f517a408",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "gradient = cv2.morphologyEx(lim_otsu, cv2.MORPH_GRADIENT, kernel)\n",
    "cv2.imwrite('imagens/outputs/gradient.png', gradient)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee610e3e90514ef",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## Rodando o tesseract na imagem após a erosão (melhor resultado)\n",
    "tesseract_config = \"--tessdata-dir tessdata --psm 6\"\n",
    "\n",
    "texto = pytesseract.image_to_string(erosion, config=tesseract_config, lang=\"por\")\n",
    "\n",
    "print(texto)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33b96bed7031b98",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "O resultado acima mostra que a operação de erosão melhorou a extração do texto da placa de veículo, ainda que não tenha sido perfeito."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92b6b270058da1bd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Detecção da Placa\n",
    "\n",
    "Para melhorarmos a detecção do texto dentro da placa do veículo vamos tentar recuperar apenas a região da placa, de maneira a reduzir a quantidade de informação que não nos interessa. Para isso, vamos utilizar o método `cv2.findContours` para encontrar os contornos da imagem e o método `cv2.Canny` para encontrar as bordas da imagem."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c3de32ca7c6c77a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "canny_image = cv2.Canny(gray_image, 100, 200)\n",
    "cv2.imwrite('imagens/outputs/canny_image.png', canny_image)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9aa35871589804cc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "contours, _ = cv2.findContours(canny_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "contours"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e500f0169b95db",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Localização da Placa\n",
    "\n",
    "Analisando a imagem que mostra apenas os contornos podemos observar que os contornos da placa do veículo não são totalmente contínuos, então faremos uso do método `cv2.approxPolyDP` para aproximar os contornos da placa do veículo, de maneira a obter um contorno que seja retangular."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7f1248fc61705c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for contour in contours:\n",
    "    episilon = 0.02 * cv2.arcLength(contour, True)\n",
    "    approx = cv2.approxPolyDP(contour, episilon, True)\n",
    "\n",
    "    if len(approx) == 4 and cv2.isContourConvex(approx):\n",
    "        loc = approx\n",
    "        break\n",
    "\n",
    "loc"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "729b4db913fee286",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Extraindo o ponto x e y, altura e largura da placa\n",
    "\n",
    "x, y, w, h = cv2.boundingRect(loc)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45071efb613714a1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "placa = gray_image[y:y + h, x:x + w]\n",
    "cv2.imwrite('imagens/outputs/placa.png', placa)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3555154db6603a80",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Agora que temos a imagem apenas da placa, podemos aplicar os conceitos vistos anteriormente para extrairmos o texto da placa da maneira mais eficiente possível."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6dc8054bd2405100"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Aplicando a limiarização Otsu na placa\n",
    "_, otsu_placa = cv2.threshold(placa, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Definição do kernel para a erosão\n",
    "kernel_placa = cv2.getStructuringElement(cv2.MORPH_RECT, (4, 4))\n",
    "erode_placa = cv2.erode(otsu_placa, kernel_placa)\n",
    "\n",
    "cv2.imwrite('imagens/outputs/erode_placa.png', erode_placa)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6026ca9c6083ae17",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Rodando o tesseract na imagem erodida da placa\n",
    "\n",
    "tesseract_config = \"--tessdata-dir tessdata --psm 6\"\n",
    "\n",
    "texto = pytesseract.image_to_string(erode_placa, config=tesseract_config, lang=\"por\")\n",
    "print(texto)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "563e09b566237288",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "A saída acima possui um caracter indesejado no começo do output. Vamos utilizar uma expressão regular para remover esse caracter, visto que todas as placas de veículos possuem o mesmo padrão de caracteres."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dff98f2f91cd8672"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "texto_extraido = re.search('\\w{3}\\d{1}\\w{1}\\d{2}', texto)\n",
    "print(texto_extraido.group(0))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f978042415da31b8",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reconhecimento automatizado\n",
    "\n",
    "A utilização da detecção de bordas de Canny pode não ser a melhor abordagem sempre. Neste exemplo usaremos o black hat para encontrarmos a posição da placa na imagem."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50f0ba8e67bfb998"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Lendo uma nova imagem\n",
    "image_file_path = os.getcwd() + '/imagens/placa_carro3.jpg'\n",
    "\n",
    "image = cv2.imread(image_file_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7ac3d49733c122b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Definindo um kernel para a transformação black hat\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 13))  # 40, 13 é o tamanho da placa\n",
    "\n",
    "black_hat = cv2.morphologyEx(image, cv2.MORPH_BLACKHAT, kernel)\n",
    "\n",
    "cv2.imwrite('imagens/outputs/black_hat_placa3.png', black_hat)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2146070eb049528b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Aplicando o sobel na direção x da imagem\n",
    "\n",
    "sobel_x = cv2.Sobel(black_hat, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=1)\n",
    "sobel_x = np.absolute(sobel_x)\n",
    "sobel_x = sobel_x.astype('uint8')\n",
    "\n",
    "cv2.imwrite('imagens/outputs/sobel_x_placa3.png', sobel_x)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1af55869d81eb58",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Máscara\n",
    "\n",
    "Agora que temos a imagem com o sobel aplicado na direção x, vamos criar uma máscara para realçar a região da placa. O primeiro passo é aplicarmos um efeito de desfoque na imagem gerada pelo Sobel a fim de reduzir alguns ruídos."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "354c92ec5e682049"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sobel_x = cv2.GaussianBlur(sobel_x, (5, 5), 0)\n",
    "sobel_x = cv2.morphologyEx(sobel_x, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imwrite('imagens/outputs/sobel_x_blur_placa3.png', sobel_x)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff782445b5ceca2d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Aplicando a limiarização de Otsu na imagem\n",
    "_, otsu_placa3 = cv2.threshold(sobel_x, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "cv2.imwrite(\"imagens/outputs/otsu_placa3.png\", otsu_placa3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "262633b7e8cd1f83",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos perceber que a limiarização de Otsu deixou evidente um retângulo majoritariamente, oq pode ser um forte indicativo de ser a placa do veículo. A seguir precisamos remover alguns ruídos que foram gerados a partir da limiarização."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2706f5cdf9fb917"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Definição do kernel para a erosão\n",
    "kernel_quadrado = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "otsu_placa3 = cv2.erode(otsu_placa3, kernel_quadrado, iterations=2)\n",
    "otsu_placa3 = cv2.dilate(otsu_placa3, kernel_quadrado, iterations=2)\n",
    "\n",
    "cv2.imwrite(\"imagens/outputs/otsu_placa3_erode_dilate.png\", otsu_placa3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd6f305601f5fc63",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Criando a máscara a partir da imagem em escala de cinza\n",
    "\n",
    "# close_gray_image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "_, mascara = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "cv2.imwrite(\"imagens/outputs/mascara_placa3.png\", mascara)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67d08e4c19342438",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "limiarizacao = cv2.bitwise_and(otsu_placa3, otsu_placa3, mask=mascara)\n",
    "limiarizacao = cv2.dilate(limiarizacao, kernel_quadrado, iterations=2)\n",
    "limiarizacao = cv2.erode(limiarizacao, kernel_quadrado)\n",
    "\n",
    "cv2.imwrite(\"imagens/outputs/limiarizacao_placa3.png\", limiarizacao)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea4e34ca6d830167",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "O passo seguinte consiste em aplicar o método `clear_border` para remover os contornos que estão nas bordas da imagem."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b34abf0da053fa52"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from skimage.segmentation import clear_border\n",
    "\n",
    "limiarizacao = clear_border(limiarizacao)\n",
    "cv2.imwrite(\"imagens/outputs/limiarizacao_placa3_clear_border.png\", limiarizacao)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "628eb75cec70f329",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# limiarizacao = cv2.erode(limiarizacao, kernel_quadrado, iterations=2)\n",
    "# limiarizacao = cv2.dilate(limiarizacao, kernel_quadrado)\n",
    "# cv2.imwrite(\"imagens/outputs/limiarizacao_placa3_erode.png\", limiarizacao)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6e9b2acc522c0ca",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Agora que melhorarmos a imagem podemos encontrar os contornos através do método `findContours` e aproximar os contornos da placa do veículo."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "985301e66b518c82"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "contornos, _ = cv2.findContours(limiarizacao, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contornos = sorted(contornos, key=cv2.contourArea, reverse=True)[:10]\n",
    "contornos"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9245b2565cd15e76",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "O laço de repetição abaixo servirá para encontrar o contorno que representa a placa do veículo. Faremos isso analisando a proporção entre a largura e a altura do contorno. Como 40/13 é a proporção da placa, vamos considerar contornos que possuem uma proporção entre 3 e 3.5."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c749021dbf792e6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for contorno in contornos:\n",
    "    x, y, w, h = cv2.boundingRect(contorno)\n",
    "    proporcao = float(w) / h\n",
    "\n",
    "    if 3 <= proporcao <= 3.5:\n",
    "        placa = image[y:y + h, x:x + w]\n",
    "        valor, regiao_interesse = cv2.threshold(placa, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "        regiao_interesse = clear_border(regiao_interesse)\n",
    "\n",
    "        cv2.imwrite(\"imagens/outputs/placa3.png\", placa)\n",
    "        cv2.imwrite(\"imagens/outputs/regiao_interesse_placa3.png\", regiao_interesse)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c123969e37dd6dd0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".BDM3D69\n",
      "\n",
      "BDM3D69\n"
     ]
    }
   ],
   "source": [
    "# Rodando o tesseract na imagem da placa\n",
    "\n",
    "tesseract_config = \"--tessdata-dir tessdata --psm 6\"\n",
    "texto = pytesseract.image_to_string(regiao_interesse, lang='por', config=tesseract_config)\n",
    "print(texto)\n",
    "\n",
    "texto_extraido = re.search('\\w{3}\\d{1}\\w{1}\\d{2}', texto)\n",
    "print(texto_extraido.group(0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T14:20:02.994390Z",
     "start_time": "2024-04-05T14:20:02.568387Z"
    }
   },
   "id": "7d7acee00e91119d",
   "execution_count": 105
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
